---
title: "Model Testing in R"
author: "Franz X. Mohr"
date: "2018-12-02"
tags:
  - t-test
  - F-test
---



<p>Model testing belongs to the main tasks of any econometric analysis. This post illustrates how to calculate basic test statistics such as the t statistic and the F-test in R.</p>
<div id="data" class="section level2">
<h2>Data</h2>
<p>To illustrate the calculation of test statistics in R, let’s use the <em>wage1</em> dataset from the <code>wooldridge</code> package and estimate a basic <a href="https://en.wikipedia.org/wiki/Mincer_earnings_function" target="_blank">Mincer earnings function</a>. This standard specification of earnings models explains the natural log of average hourly earnings <code>lwage</code> by years of education <code>educ</code> and experience <code>exper</code>. The standard specification also includes the squared values of experience <code>expersq</code> to take into account potential decreasing marginal effects.</p>
<pre class="r"><code># Load dataset
library(wooldridge)
data(&quot;wage1&quot;)

# Estimate a model
model &lt;- lm(lwage ~ educ + exper + expersq, data = wage1)</code></pre>
</div>
<div id="t-test" class="section level2">
<h2>t test</h2>
<p>t tests are used to assess the statistical significance of single variables. In R t values for each variable in a regression model are usually already calculated by the <code>summary</code> function.</p>
<pre class="r"><code>summary(model)</code></pre>
<pre><code>## 
## Call:
## lm(formula = lwage ~ educ + exper + expersq, data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96387 -0.29375 -0.04009  0.29497  1.30216 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.1279975  0.1059323   1.208    0.227    
## educ         0.0903658  0.0074680  12.100  &lt; 2e-16 ***
## exper        0.0410089  0.0051965   7.892 1.77e-14 ***
## expersq     -0.0007136  0.0001158  -6.164 1.42e-09 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4459 on 522 degrees of freedom
## Multiple R-squared:  0.3003, Adjusted R-squared:  0.2963 
## F-statistic: 74.67 on 3 and 522 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The t values for our benchmark model indicate that, except for the constant, all variables are statistically significant. You might think about dropping the intercept term at this point, but let’s forget about this for the moment.</p>
</div>
<div id="f-test" class="section level2">
<h2>F test</h2>
<p>F tests can be used to check, whether one or multiple variables in a model are statistically significant. Basically, the test compares two models with each other, where one model is a special case of the other. This means that we compare a model with more variables - the so-called <em>unrestricted</em> model - to a model with less but otherwise the same variables, i.e. the <em>restriced</em> or nested model. If the additional predictive power of the unrestricted model is sufficiently high, the variables are jointly significant.</p>
<p>In our example, we add the <code>tenure</code> variable and its square <code>tenuresq</code> to the model equation. This is the unrestricted model, which we have to estimate before we can calculate the F test.</p>
<pre class="r"><code># Estimate unrestricted model
model_unres &lt;- lm(lwage ~ educ + exper + expersq + tenure + tenursq, data = wage1)

summary(model_unres)</code></pre>
<pre><code>## 
## Call:
## lm(formula = lwage ~ educ + exper + expersq + tenure + tenursq, 
##     data = wage1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.96984 -0.25313 -0.03204  0.27141  1.28302 
## 
## Coefficients:
##               Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.2015715  0.1014697   1.987   0.0475 *  
## educ         0.0845258  0.0071614  11.803  &lt; 2e-16 ***
## exper        0.0293010  0.0052885   5.540 4.80e-08 ***
## expersq     -0.0005918  0.0001141  -5.189 3.04e-07 ***
## tenure       0.0371222  0.0072432   5.125 4.20e-07 ***
## tenursq     -0.0006156  0.0002495  -2.468   0.0139 *  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.425 on 520 degrees of freedom
## Multiple R-squared:  0.3669, Adjusted R-squared:  0.3608 
## F-statistic: 60.26 on 5 and 520 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The t values of the new model indicate that all variabes - including the constant - are statistically significant and <code>tenure</code> provides additional explanatory power to the model. Since <code>tenure</code> also enters in its squared form, we are interested in the joint significance of the tenure terms. This can be checked with an F test. In R we can use the <code>anova</code> function for this, where we proved the two estimated models as arguments.</p>
<pre class="r"><code>anova(model, model_unres)</code></pre>
<pre><code>## Analysis of Variance Table
## 
## Model 1: lwage ~ educ + exper + expersq
## Model 2: lwage ~ educ + exper + expersq + tenure + tenursq
##   Res.Df     RSS Df Sum of Sq      F    Pr(&gt;F)    
## 1    522 103.790                                  
## 2    520  93.911  2    9.8791 27.351 5.079e-12 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>As you can see from the output, the tenure terms are joinly significant.</p>
</div>
<div id="literature" class="section level2">
<h2>Literature</h2>
<p>Kennedy, P. (2014). A Guide to Econometrics. Malden (Mass.): Blackwell Publishing 6th ed.</p>
</div>
